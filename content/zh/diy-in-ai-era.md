---
title: 在人工智能时代动手做事情
date: 2025-03-31
slug: do-it-yourself
author: HtwoO
categories:
    - 技术
tags:
---

继区块链（ blockchain ）、非同质化代币（ Non Fungible Token, NFT ）、元宇宙（ Metaverse ）之后，人工智能（ AI ）成为了资本市场最新的[宠儿](https://twitter.com/Peter_shirley/status/1627178089917874176)。不过，我想说的是，即使在人工智能迅速普及的时代，我们自己动手去做一些事情仍然有其意义和必要性。

在人工智能普及之前，人们已经在使用各种半自动或自动化方法来提高效率了，比如用于快速部署一些服务用的一键脚本、以及用于和计算机系统或网络服务交互的应用程序接口（ Application Programming Interface, API ）。

当我们只想把任务做完，完全不理解、甚至不关心这些自动化任务背后的机理，可能会对后续的任务有负面的效果。比如软件行业很常见的 `curl ... | bash` 一键脚本自动部署，是使用命令行网络请求工具 curl 快速下载一个脚本文件，然后用 bash shell 去执行它，会有些问题，比如无意中安装上木马或病毒软件，之后想要彻底清除木马或病毒，就没有那么容易了。就好像鸡蛋被打破了、膏药被挤出来了，想要恢复原样，是非常麻烦、有时候甚至是不可能的，除非时光可以倒流 ^_^

## 技术／技能的普及和传播要求学习者动手实践

在上面一键部署的场景中，需要用户对软件来源、分发渠道有足够信任的时候，才可以方便的使用。但如果软件来源或分发渠道不太可靠，就需要其他方式来验证软件是否有问题。在这种情形下，如果把这些所谓自动化任务拆开，我们可以先用 curl 把脚本先下载回来，自己用一个编辑器打开脚本看看它具体做了什么，了解它大概会对我们的计算机系统有哪些影响，再用 bash shell 去执行它，或者自己把脚本的自动任务手动做一遍，从而对部署过程有更多的控制。当这些软件运行出现异常的时候，我们也会更清楚应该从哪里入手去排查问题。

自己动手去完成一个任务，可以让自己对任务所需的流程有更深刻的理解，之后如果该流程出现了异常，你可以更自信的处理问题。

这也是学习一个事物的时候应该经过的过程、我们上学的时候都需要做一些习题，如果习题的问题提得好，就能够对学习者有很好的指引作用，反之，如果习题设计得不理想，导致学习者要机械重复简单的事，学习者就会感到烦躁，从而让学习效果大打折扣。要对一个事物有比较深刻的理解，需要主动学习，主动学习的时候，学习者需要经过某种思维过程，可能是前人经历过的过程，也可能是自己探索出来的，如果我们忽略了这些过程，理解得可能就不够深刻。

现实生活中，一种很常见的动手方式是拆解物品，往往在自己使用的物品出现问题的时候，人们才会想到把物品拆开来看看，拆开过某种物品以后，会让人对它有更多了解，比如它是使用了什么接口、有哪些组件、运作原理是怎样的。当然，因为现代社会分工的存在，很多人在物品出问题的时候，完全没有信心和意愿去拆解，而是立即去呼叫维修服务，或者直接换新。我拆修过的物品包括塔式计算机、笔记本电脑、手机、风扇、电吹风、洗衣机（没有拆得很散）等。很多人以前都拆过[收音机](https://zh.wikipedia.org/wiki/%E6%94%B6%E9%9F%B3%E6%9C%)，这东西可能以后的小朋友们只能从博物馆了解了，我也拆过，只不过现在对收音机的电路仍然没多少理解 p_q

## AI 经常杜撰不存在的实例／示例

最近我用过几次由 AI 生成的（命令行）工具使用示例，有些能一次生成可以直接使用的结果，另外一些时候，使用示例是 AI 杜撰出来、和文档不符的，有些示例经过多次提示修正之后，仍然是有问题的。我想，这应该也是在最大的中文技术讨论区之一、有六千多成员的 [Arch Linux CN Telegram 群组](https://t.me/archlinuxcn_group)，管理员禁止成员发布（未经验证的） AI 生成的答案的原因。在技术领域，很多程序／工具要求精确规范的输入数据，才可以正常或高效的进行数据处理，并生成有用的输出。

在这些场景中， AI 有时不但帮不上忙，还可能因为杜撰出来的使用场景而污染有用的数据，变成垃圾内容农场，结果轻则加剧用户[体验恶化](https://en.wikipedia.org/wiki/Enshittification)，重则造成虚假信息传播。 2023 年，美国律师史蒂文·施瓦茨就因为对 ChatGPT 生成的内容不加验证，在法庭文件中引用了并不存在的法律案例。

## AI 不能坐牢，还需要人类来做决断 ¯_(ツ)_/¯

这有点像企业控制权的抽象，要做到有效管理，管理机关总归需要有个机制能获取到一个机构的实际控制人。以后 AI 估计也许要类似的机制，比如 AI 的言论，或动作，要在判例中作为证据出现，估计需要用其他元数据来确认责任的边界。

## 后记

修订自 Deepseek R1 的总结，我感觉还不错： AI 的出现，让人类多了一个工具，但人类的核心价值不在于「动手的频率」，而在于**保持对世界的感知力、批判性思维和主动创造的意愿**。人类应该争取做「 AI 的导演」，而非「观众」**，正如木匠不会因电锯的出现放弃雕刻，我们应利用 AI 扩展能力边界，而非让工具定义人的价值。

## 参考资料

https://security.stackexchange.com/questions/213401/is-curl-something-sudo-bash-a-reasonably-safe-installation-method

[生成式 AI “幻觉”困境如何破解](https://www.stdaily.com/web/gjxw/2025-01/28/content_291320.html)

